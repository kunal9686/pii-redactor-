

# ğŸ”’ PII Redactor API

This project is a **Flask-based web service** that allows users to upload PDF documents and receive **PII-redacted (Personally Identifiable Information)** versions. It uses **OCR**, **transformers-based NER models**, and **PDF manipulation** to ensure sensitive information is identified and redacted from the document accurately.

---

## ğŸ“‚ Project Structure

```
â”œâ”€â”€ app.py                 # Contains core logic for PII redaction
â”œâ”€â”€ main.py                # Flask server handling file uploads, redaction, and downloads
â”œâ”€â”€ uploads/               # Stores uploaded PDF files
â”œâ”€â”€ processed/             # Stores redacted output PDFs
â”œâ”€â”€ status/                # JSON files tracking redaction status
â”œâ”€â”€ samples/               # Sample PDF files for demo
â”œâ”€â”€ templates/index.html   # Optional frontend (if provided)
â”œâ”€â”€ models/                # Cached HuggingFace models
â”œâ”€â”€ src/                   
â”‚   â”œâ”€â”€ logger.py          # Custom logging utility
â”‚   â””â”€â”€ custom_exception.py# Custom exception class
```

---

## âš™ï¸ Features

* âœ… Upload a PDF document via an API
* ğŸ§  Detect PII using a HuggingFace transformer model (`ab-ai/pii_model`)
* ğŸ–ï¸ Redact detected PII in text and images
* ğŸ§¾ Return a redacted PDF for download
* ğŸ“ˆ Track redaction progress via a `/status/<file_id>` endpoint
* ğŸ” Preview snippets of original and redacted text

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites

* Python 3.8+
* Tesseract OCR installed and accessible
* Poppler installed for PDF image conversion

**Install requirements:**

```bash
pip install -r requirements.txt
```

**Ensure dependencies are installed and paths are updated:**

* Tesseract Path: Update `pytesseract.pytesseract.tesseract_cmd` in `app.py`
* Poppler Path: Used in `convert_from_path()` â€” update to your local Poppler bin path

---

### â–¶ï¸ Running the App

Start the Flask app:

```bash
python main.py
```

Visit: [http://localhost:5001](http://localhost:5001)

---

## ğŸ§ª API Endpoints

### ğŸ“¤ `POST /upload`

Upload a PDF for redaction.

* **Form field**: `file` (PDF only)
* **Returns**: `file_id`, `message`

### ğŸ“¥ `GET /status/<file_id>`

Check redaction progress.

* **Returns**: redaction status, statistics, accuracy, types of detected PII

### ğŸ“„ `GET /preview/original/<file_id>`

Get the first 500 characters of the **original** unredacted text.

### ğŸ”’ `GET /preview/redacted/<file_id>`

Get the first 500 characters of the **redacted** text.

### ğŸ“¦ `GET /download/<file_id>`

Download the redacted PDF once ready.

### ğŸ¯ `GET /sample`

Run redaction on a predefined sample file.

### âœ… `GET /test`

Test if the API is live and responsive.

---

## ğŸ§  How It Works

1. **Extract text** from uploaded PDF using `pytesseract` with image preprocessing
2. **Detect PII** entities via HuggingFace NER pipeline
3. **Redact text** by replacing PII with block characters (`â–ˆ`)
4. **Create redacted PDF** using positional OCR data and PIL drawing
5. **Track status** via JSON files and return stats like:

   * Total pages
   * Accuracy of redaction
   * Entity types (e.g., NAME, EMAIL, PHONE)

---

## ğŸ“Š Sample Output

```json
{
  "status": "completed",
  "pii_count": 8,
  "accuracy": 0.95,
  "pii_types": {
    "PER": 3,
    "LOC": 3,
    "PHONE": 2
  }
}
```

---

## ğŸ›  Configuration Tips

* ğŸ“ Update hardcoded file paths like `samples/khushi_bsl.pdf` or Poppler/Tesseract paths for your system.
* ğŸ“¤ Ensure folders like `/uploads`, `/processed`, `/status` exist (created automatically if missing).

---

## ğŸ§° Dependencies

* `pytesseract`
* `pdf2image`
* `transformers`
* `torch`
* `flask`
* `flask_cors`
* `reportlab`
* `Pillow`
* `PyPDF2`

---

## ğŸ“Œ To Do / Enhancements

* Add UI for drag-and-drop PDF uploads
* Dockerize the app for platform-independent deployment
* Add email notifications when redaction is complete
* Use GPU acceleration more efficiently for larger batches

---

## ğŸ§‘â€ğŸ’» Author

> Built by \[DEVANSH , KUNAL] â€” focused on privacy-first document handling using deep learning.

